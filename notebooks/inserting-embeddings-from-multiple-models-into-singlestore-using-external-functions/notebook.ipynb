{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "48bd8614-f726-44e2-94bd-050cb58a67a6",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(209, 153, 255, 0.25); padding: 5px;\">\n",
        "    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n",
        "        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/vector-circle.png\" />\n",
        "    </div>\n",
        "    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n",
        "        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n",
        "        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Inserting embeddings from multiple models into SingleStore Using External Functions</h1>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9591e358-2168-4e37-a839-4f02db584090",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "In the realm of database management and artificial intelligence, the ability to directly incorporate vector embeddings from leading providers into your database can significantly enhance your application's capabilities. This notebook delves into the practicalities of using SingleStoreDB\u2019s external functions to dynamically fetch and update vector embeddings for textual data, focusing on models from OpenAI and Hugging Face. This approach simplifies the process of enriching your database with deep learning insights, directly within SQL queries.\n",
        "\n",
        "SingleStoreDB facilitates the storage of vector embeddings in two primary ways: using the `blob` type with the `JSON_ARRAY_PACK` function to convert a JSON array of floating-point numbers into an encoded blob, and the `vector` type, introduced in version 8.5, designed specifically for efficient handling of high-dimensional data.\n",
        "\n",
        "### Blob Type and JSON_ARRAY_PACK\n",
        "\n",
        "The `blob` type, combined with `JSON_ARRAY_PACK`, provides a method to store vector embeddings as encoded blobs. This approach allows for the flexibility of storing embeddings from multiple models in the same column by including a `model_id` column to identify which embedding corresponds to which model. However, it does not leverage SingleStoreDB's advanced vector operation capabilities.\n",
        "\n",
        "### Vector Type for Enhanced Efficiency\n",
        "\n",
        "From version 8.5, SingleStoreDB supports the `vector` data type, offering an ordered collection of numeric values with a fixed number of dimensions. This type is optimized for various data representations, including embeddings from large language models (LLMs), making it easier to insert, load, and query vector data. The `vector` type requires specifying the dimension size and currently supports `F32` as the element type. When choosing the `vector` type, it's important to note that, depending on the model of embedding, you will have to create a new column for each model since the dimensions must be specified for the `vector` type. This requirement can influence database schema design based on the diversity of embedding models used.\n",
        "\n",
        "### Vector Index and ANN Search\n",
        "\n",
        "SingleStoreDB's support for vector similarity scoring and Approximate Nearest Neighbor (ANN) search enables efficient k-nearest neighbor queries, especially beneficial for large datasets and high concurrency requirements. While exact kNN search provides precise results, ANN search offers a faster, though approximate, alternative, striking a balance between accuracy and speed. This feature is ideal for applications such as semantic search of text, retrieval-augmented generation (RAG), and image matching based on vector embeddings similarity.\n",
        "\n",
        "### Key Considerations\n",
        "\n",
        "- **Storage Flexibility**: Using the `blob` type for embedding storage offers flexibility in handling multiple models within a single column but precludes the use of vector indices and ANN search capabilities.\n",
        "- **Efficiency and Specificity**: The `vector` type, along with vector indices, enables efficient ANN searches, necessitating separate columns for embeddings from different models due to dimension specification requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b68fe714-dc36-445b-85ff-69a74099a557",
      "metadata": {},
      "source": [
        "### Architecture diagram :\n",
        "<center>\n",
        "    <img src=\"images/architecture.png\" alt=\"Architecture Diagram\" width=\"800\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26641499-1240-4c77-95f4-67d7ae79d66b",
      "metadata": {},
      "source": [
        "## Database Setup for Embeddings Demo\n",
        "\n",
        "This section outlines the initial setup required for our embeddings demo, including the creation of databases and tables to store sentences and their corresponding embeddings.\n",
        "\n",
        "### Steps:\n",
        "1. **Drop Existing Database (if exists)**: Ensures that there is no existing `embeddings_demo` database that might conflict with our setup.\n",
        "2. **Create New Database**: Initializes a fresh database named `embeddings_demo` for our demo.\n",
        "3. **Switch to New Database**: Sets the context to the newly created database for subsequent operations.\n",
        "4. **Create `random_sentences` Table**: This table is designed to store sentences along with a unique identifier (`uuid`) and a timestamp. The structure supports the insertion of sample sentences for which we will generate embeddings.\n",
        "5. **Insert Sample Data**: Populates the `random_sentences` table with a variety of sentences. These sentences serve as our data source for embedding generation.\n",
        "6. **Create `random_sentences_embeddings` Table**: Designed to store the sentences along with their embeddings generated by two different models - OpenAI's Ada model and the Hugging Face MiniLM L12 v2 model. The embeddings are stored in vector format with specified dimensions, utilizing SingleStore's vector data type for efficient embedding storage and operations.\n",
        "7. **Create `random_sentences_embeddings_2` Table**: A table intended to store sentences and their embeddings in a blob format, providing an alternative structure for embedding storage.\n",
        "\n",
        "### Purpose:\n",
        "- The `random_sentences` table serves as the input for our embedding generation process.\n",
        "- The `random_sentences_embeddings` table showcases how to store embeddings in a structured vector format, allowing for direct operations on embeddings within the database. This table leverages SingleStore's vector data type, enabling ordered collections of numeric values with fixed dimensions for embeddings.\n",
        "- The duplicated creation command for `random_sentences_embeddings_2` appears to be an oversight and should be considered for removal to avoid confusion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e4a7515c-62cb-41a8-8405-c48ed4f56f78",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "DROP DATABASE IF EXISTS embeddings_demo;\n",
        "CREATE DATABASE embeddings_demo;\n",
        "USE embeddings_demo;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "15b2e3b4-b16f-4afd-9ca7-273de3f86d9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE TABLE random_sentences (\n",
        "  uuid VARCHAR(256),\n",
        "  sentence VARCHAR(512),\n",
        "  timestamp TIMESTAMP DEFAULT NOW()\n",
        ");\n",
        "-- inserting sample data\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'Hello there, how are you today?', DEFAULT);\n",
        "\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'The quick brown fox jumped over the lazy dog', DEFAULT);\n",
        "\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'She sells seashells by the seashore', DEFAULT);\n",
        "\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'The early bird gets the worm', DEFAULT);\n",
        "\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'Fortune favors the bold', DEFAULT);\n",
        "\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'A penny saved is a penny earned', DEFAULT);\n",
        "\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'You cant teach an old dog new tricks', DEFAULT);\n",
        "\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'The grass is always greener on the other side', DEFAULT);\n",
        "\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'Birds of a feather flock together', DEFAULT);\n",
        "\n",
        "INSERT INTO random_sentences VALUES (uuid(),  'Actions speak louder than words', DEFAULT);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0e778407-fea2-4409-951f-cfec1419bda4",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT * FROM random_sentences;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c35e8c94-0e54-402c-a112-c8d2ae4ad219",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE TABLE random_sentences_embeddings (\n",
        "  uuid VARCHAR(256),\n",
        "  sentence VARCHAR(512),\n",
        "  openai_ada002_embeddings VECTOR(1536),\n",
        "  hf_miniLM_L12_v2_embeddings VECTOR(384)\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ed1f55dd-c450-49bc-97ca-2ba462efc778",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE TABLE random_sentences_embeddings_2 (\n",
        "  uuid VARCHAR(256),\n",
        "  sentence VARCHAR(512),\n",
        "  model_id VARCHAR(512),\n",
        "  embedding BLOB\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0113780-b9f6-4a2b-978a-0f1ff32c2a03",
      "metadata": {},
      "source": [
        "## Inserting Embeddings into SingleStoreDB\n",
        "\n",
        "This segment of the notebook demonstrates the activation of external functions within SingleStoreDB and outlines the steps for creating and utilizing an external function,\n",
        "    `get_embedding`, to dynamically generate text embeddings.\n",
        "    Additionally, we detail the implementation of stored procedures designed to automate the insertion of these embeddings into specified tables.\n",
        "\n",
        "\n",
        "### The `get_embedding` External Function\n",
        "\n",
        "We introduce an external function, `get_embedding`, that communicates with a remote service to obtain embeddings for given text inputs. This function signifies the bridge between SingleStoreDB and machine learning models, facilitating the direct insertion of complex embeddings into the database.\n",
        "\n",
        "- **About External Functions**: External functions in SingleStoreDB allow for operations to be executed outside the database process, supporting both scalar and table-valued returns. This feature is instrumental in integrating machine learning insights into SQL workflows, enhancing data with vector embeddings from models like OpenAI or Hugging Face. Check more about external functions [here](https://docs.singlestore.com/cloud/reference/sql-reference/procedural-sql-reference/create-or-replace-external-function/)\n",
        "\n",
        "- **Code for external function**: To explore and test the demo, please navigate to the 'singlestore spaces' repository. Within the designated notebook's repository, you will discover the relevant code file `external_function_api.py`. This code is ready for use and has been set up to facilitate an interactive demonstration. For quicker access check **appendix at the end of the notebook**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b2a76d32-660a-451d-8cb8-5ba0862dbada",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "CREATE OR REPLACE EXTERNAL FUNCTION get_embedding(str1 TEXT, model_name TEXT) RETURNS TEXT\n",
        "AS REMOTE SERVICE 'http://<your_ip_address_where_api_is_running>:5000/functions/get_embedding'\n",
        "FORMAT JSON;\n",
        "\n",
        "-- Test external function\n",
        "-- SELECT get_embedding(\"blueberry\", 'openai_embedding')AS res ;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e85466fe-28cf-4beb-a54e-795f52e771be",
      "metadata": {},
      "source": [
        "### Dynamic Data Insertion with `InsertDynamicData_1`\n",
        "\n",
        "A stored procedure, `InsertDynamicData_1`, dynamically constructs and executes an SQL query to insert generated embeddings into the `random_sentences_embeddings_2` table. This process exemplifies the seamless integration of machine learning embeddings into database records, leveraging the `get_embedding` external function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "826d018a-3b33-4319-93f5-efc8d8b68dc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE OR REPLACE PROCEDURE InsertDynamicData_1(source_table_id TEXT, target_table_id TEXT, source_column_id TEXT, embedding_model_id TEXT)\n",
        "AS\n",
        "DECLARE\n",
        "sql_query TEXT;\n",
        "BEGIN\n",
        "    sql_query = CONCAT('INSERT INTO ', target_table_id, ' (uuid, sentence, model_id, embedding) SELECT uuid, sentence, ''', embedding_model_id, ''' ,JSON_ARRAY_PACK(get_embedding(', source_column_id, ', ''', embedding_model_id, ''')) FROM ', source_table_id);\n",
        "    EXECUTE IMMEDIATE sql_query;\n",
        "END;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9c1f4b0f-30bf-4c4f-aae9-052587340997",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CALL InsertDynamicData_1('random_sentences', 'random_sentences_embeddings_2', 'sentence', 'openai_embedding');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e0f26928-c7b0-4202-9bb3-87ea1388e8cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CALL InsertDynamicData_1('random_sentences', 'random_sentences_embeddings_2', 'sentence', 'hf_embedding');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9a3070cd-130d-430c-bf66-4262ecdcce5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "select COUNT(*) from random_sentences_embeddings_2;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00f84e3-7cba-43ab-b990-c9416a9531a2",
      "metadata": {},
      "source": [
        "### Advanced Embedding Insertion with `InsertDynamicData_2`\n",
        "\n",
        "Another stored procedure, `InsertDynamicData_2`, is designed to handle multiple embedding models, inserting their outputs into designated vector columns within the `random_sentences_embeddings` table. This procedure illustrates the flexibility and power of SingleStoreDB in accommodating complex data types like vectors, directly derived from machine learning embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a7f8cfd0-7503-488e-b7c7-466378bc1109",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE OR REPLACE PROCEDURE InsertDynamicData_2(source_table_id TEXT, target_table_id TEXT, source_column_id TEXT)\n",
        "AS\n",
        "DECLARE\n",
        "sql_query TEXT;\n",
        "BEGIN\n",
        "    sql_query = CONCAT(\n",
        "        'INSERT INTO ', target_table_id,\n",
        "        ' (uuid, sentence, openai_ada002_embeddings, hf_miniLM_L12_v2_embeddings) ',\n",
        "        'SELECT uuid, sentence, ',\n",
        "        'get_embedding(', source_column_id, ', ''openai_embedding''), ',\n",
        "        'get_embedding(', source_column_id, ', ''hf_embedding'') ',\n",
        "        'FROM ', source_table_id\n",
        "    );\n",
        "    EXECUTE IMMEDIATE sql_query;\n",
        "END;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0cdce870-4233-4843-b875-c7e54c01c960",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CALL InsertDynamicData_2('random_sentences', 'random_sentences_embeddings', 'sentence');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "208631e9-6273-4f47-83e1-4566f16fbc40",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT COUNT(*) FROM random_sentences_embeddings;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e1a82b-e95e-4be5-a9d0-52c9237f5336",
      "metadata": {},
      "source": [
        "### Lets try to query these embeddings to get matching score using dot_product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7650cacb-a274-4f7b-9943-647e706162d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT\n",
        "  r1.sentence AS sentence1,\n",
        "  r2.sentence AS sentence2,\n",
        "  ROUND( DOT_PRODUCT(r1.openai_ada002_embeddings, r2.openai_ada002_embeddings), 2) AS openai_score,\n",
        "  ROUND( DOT_PRODUCT(r1.hf_miniLM_L12_v2_embeddings, r2.hf_miniLM_L12_v2_embeddings), 2) AS hf_score\n",
        "FROM\n",
        "  random_sentences_embeddings r1,\n",
        "  random_sentences_embeddings r2\n",
        "ORDER BY\n",
        "  openai_score DESC, hf_score DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38f2c7af",
      "metadata": {},
      "source": [
        "## Appendix\n",
        "Code for external function API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "00bc005f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile external_function_api.py\n",
        "\n",
        "import json\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "import openai\n",
        "import torch\n",
        "from flask import Flask\n",
        "from flask import request\n",
        "from openai import OpenAI\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Set up OpenAI\n",
        "api_key = 'add your openai key'\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# Load Hugging Face model\n",
        "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "hf_model = AutoModel.from_pretrained(model_name)\n",
        "hf_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Hugging Face embedding function\n",
        "\n",
        "\n",
        "def get_hf_embedding(texts):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        inputs = hf_tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            embedding = hf_model(**inputs).last_hidden_state.mean(dim=1)\n",
        "            norm = torch.linalg.vector_norm(embedding, ord=2, dim=1, keepdim=True)\n",
        "            normalized_embedding = embedding / norm\n",
        "            embeddings.append(normalized_embedding.squeeze().tolist())\n",
        "    return embeddings\n",
        "\n",
        "# OpenAI embedding function\n",
        "\n",
        "\n",
        "def get_ada_002_embedding(texts, model='text-embedding-ada-002'):\n",
        "    responses = openai.embeddings.create(input=texts, model=model)\n",
        "    return [response.embedding for response in responses.data]\n",
        "\n",
        "\n",
        "def process_batch(batch, model_name):\n",
        "    texts = [text for text in batch if isinstance(text, str) and text.strip()]\n",
        "    if not texts:\n",
        "        return []\n",
        "    if model_name == 'openai_embedding':\n",
        "        try:\n",
        "            return get_ada_002_embedding(texts, 'text-embedding-ada-002')\n",
        "        except Exception as e:\n",
        "            print(f'Error in OpenAI processing: {e}')\n",
        "            return []\n",
        "    elif model_name == 'hf_embedding':\n",
        "        return get_hf_embedding(texts)\n",
        "    else:\n",
        "        print(f'Invalid model name: {model_name}')\n",
        "        return []\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/functions/get_embedding', methods=['POST'])\n",
        "def get_embedding():\n",
        "    \"\"\" incoming data is this format :\n",
        "    {\"data\":\n",
        "    [[<row id>, <data string >, <model_name string>],\n",
        "    [<row id>, <data string >, <model_name string>],\n",
        "    ... ]}\n",
        "     \"\"\"\n",
        "    start_time = time.time()\n",
        "    row_ids, args, model_names = [], [], []\n",
        "    for row_id, data, model_name in request.json['data']:\n",
        "        row_ids.append(row_id)\n",
        "        args.append(data)\n",
        "        model_names.append(model_name)\n",
        "\n",
        "    batch_size = 1024\n",
        "    futures = []\n",
        "    with ThreadPoolExecutor(max_workers=len(args) // batch_size) as executor:\n",
        "        for i in range(0, len(args), batch_size):\n",
        "            batch = args[i:i + batch_size]\n",
        "            # Assuming all texts in the batch use the same model\n",
        "            model_name = model_names[i]\n",
        "            futures.append(executor.submit(process_batch, batch, model_name))\n",
        "\n",
        "    flat_results = [future.result() for future in futures]\n",
        "    time_taken = time.time() - start_time\n",
        "    app.logger.info(f'Time taken: {time_taken} seconds')\n",
        "    res = map(json.dumps, flat_results)\n",
        "    return dict(data=list(zip(row_ids, res)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, host='0.0.0.0', port=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5362bb5a-cb27-4be3-bde7-5092f22f2b2b",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n",
        "<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"
      ]
    }
  ],
  "metadata": {
    "jupyterlab": {
      "notebooks": {
        "version_major": 6,
        "version_minor": 4
      }
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
