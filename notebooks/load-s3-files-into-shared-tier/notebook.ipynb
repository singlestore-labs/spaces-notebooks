{
  "cells": [
    {
      "id": "e665a836",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(210, 255, 153, 0.25); padding: 5px;\">\n",
        "    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n",
        "        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/chart-network.png\" />\n",
        "    </div>\n",
        "    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n",
        "        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n",
        "        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Load files from S3 into Shared Tier</h1>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook guides you through data ingestion of CSV files from an AWS S3 location into your shared tier workspace."
      ],
      "id": "8d216f60"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a Pipeline from CSV files in AWS S3"
      ],
      "id": "f2a0cd83"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we want to create a pipeline that ingests from a CSV file stored in an AWS S3 bucket. We will guide you through an example with stock market data."
      ],
      "id": "ea5f52dc"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p>Make sure to select your database from the drop-down menu at the top of this notebook. It updates the <tt>connection_url</tt> to connect to that database.</p>\n",
        "    </div>\n",
        "</div>"
      ],
      "id": "03567fa8"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Table"
      ],
      "id": "4dc71912"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start by creating a table to store the ingested data. In our example, we will create a `Stocks` table that will store trading data for a specific stock on a given date."
      ],
      "id": "7758dcbd"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "CREATE TABLE stocks /* Creating table for sample data. */(\n",
        "\t`date` date NULL,\n",
        "\t`open` double NULL,\n",
        "\t`high` double NULL,\n",
        "\t`low` double NULL,\n",
        "\t`close` double NULL,\n",
        "\t`volume` bigint(20) NULL,\n",
        "\t`Name` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL,\n",
        "\t SHARD KEY ()\n",
        ");"
      ],
      "id": "c70f4820"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a pipeline"
      ],
      "id": "f392979e"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then create a pipeline by pointing the data source to the S3 bucket containing the dataset. In our case, we have a CSV file `all_stocks_5yr.csv` and will be ingesting it into our `Stocks` table via a pipeline `stocks_pipeline`.\n",
        "\n",
        "To create your own pipeline, you will need the following information:\n",
        "\n",
        "- The path of the bucket, such as: `'helios-self-poc-stockticker/all_stocks_5yr.csv'`\n",
        "- The name of the bucket\u2019s region, such as: `us-east-1`\n",
        "- Your AWS account\u2019s access credentials: `<aws_access_key_id>` and `<aws_secret_access_key>`\n",
        "\n",
        "*For more on how to retrieve the above information, read our [Pipeline Documentation](https://docs.singlestore.com/cloud/load-data/load-data-with-pipelines/how-to-load-data-using-pipelines/load-data-from-amazon-web-services-aws-s-3/)."
      ],
      "id": "ee51f3db"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE OR REPLACE PIPELINE stocks_pipeline /* Creating pipeline for sample data. */\n",
        "    AS LOAD DATA S3 'helios-self-poc-stockticker/all_stocks_5yr.csv'\n",
        "    CONFIG '{\"region\": \"us-east-1\"}'\n",
        "    CREDENTIALS '{\"aws_access_key_id\": \"<your_key>\",\n",
        "                  \"aws_secret_access_key\": \"<your_secret>\"}'\n",
        "    BATCH_INTERVAL 45000\n",
        "    SKIP DUPLICATE KEY ERRORS -- SKIP ALL ERRORS can be used to skip all errors that can be tracked through \"Monitor the pipeline for errors\"\n",
        "    INTO TABLE stocks\n",
        "    FIELDS TERMINATED BY ',' ENCLOSED BY '\"' ESCAPED BY '\\\\'\n",
        "    LINES TERMINATED BY '\\n' STARTING BY ''\n",
        "    IGNORE 1 LINES\n",
        "    FORMAT CSV\n",
        "    (\n",
        "    \t`stocks`.`date`,\n",
        "    \t`stocks`.`open`,\n",
        "    \t`stocks`.`high`,\n",
        "    \t`stocks`.`low`,\n",
        "    \t`stocks`.`close`,\n",
        "    \t`stocks`.`volume`,\n",
        "    \t`stocks`.`Name`\n",
        "    );"
      ],
      "id": "3ab6005c"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Start and monitor the pipeline"
      ],
      "id": "3c83f8dd"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The CREATE PIPELINE statement creates a new pipeline, but the pipeline has not yet been started, and no data has been loaded. To start a pipeline in the background, run:"
      ],
      "id": "76a8671c"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "START PIPELINE stocks_pipeline;"
      ],
      "id": "53403dba"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "show pipelines;"
      ],
      "id": "f5f76fd4"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If there is no error or warning, you should see no error message."
      ],
      "id": "a7401fca"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "SELECT * FROM information_schema.pipelines_errors\n",
        "    WHERE pipeline_name = 'stocks_pipeline';"
      ],
      "id": "3a2cbf18"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query the table"
      ],
      "id": "47e41b20"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "SELECT * FROM stocks LIMIT 5;"
      ],
      "id": "69059384"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup resources"
      ],
      "id": "06a1ce78"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "DROP PIPELINE IF EXISTS test.stocks_pipeline;\n",
        "DROP TABLE IF EXISTS test.stocks;"
      ],
      "id": "2864526b"
    },
    {
      "id": "498edece",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n",
        "<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"
      ]
    }
  ],
  "metadata": {
    "jupyterlab": {
      "notebooks": {
        "version_major": 6,
        "version_minor": 4
      }
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
