{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "deb8dbf4-2368-41b4-9f09-b14c96ccb344",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(210, 255, 153, 0.25); padding: 5px;\">\n",
        "    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n",
        "        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/chart-network.png\" />\n",
        "    </div>\n",
        "    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n",
        "        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n",
        "        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Load files from S3 into Shared Tier</h1>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "50093846-9ea3-441d-89f0-fbe0576f78bf",
      "metadata": {},
      "source": [
        "This notebook guides you through data ingestion of CSV files from an AWS S3 location into your shared tier workspace."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b2ed410a-87b8-452a-b906-431fb0e949b3",
      "metadata": {},
      "source": [
        "# Create a Pipeline from CSV files in AWS S3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9996b479-586d-4af3-b0ee-b61eead39ebc",
      "metadata": {},
      "source": [
        "In this example, we want to create a pipeline that ingests from a CSV file stored in an AWS S3 bucket. We will guide you through an example with stock market data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6dfc5b0b-9308-46c9-8cc8-be08fb07c1b6",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p>Make sure to select your database from the drop-down menu at the top of this notebook. It updates the <tt>connection_url</tt> to connect to that database.</p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "98a8e14f-808e-43ff-b670-b6656091b81a",
      "metadata": {},
      "source": [
        "## Create a Table"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a70e168d-de32-4988-90c4-651089ac25a0",
      "metadata": {},
      "source": [
        "Start by creating a table to store the ingested data. In our example, we will create a `Stocks` table that will store trading data for a specific stock on a given date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "860e1517-bd31-415f-8750-14f7bcbb85bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "CREATE TABLE stocks (\n",
        "\t`date` date NULL,\n",
        "\t`open` double NULL,\n",
        "\t`high` double NULL,\n",
        "\t`low` double NULL,\n",
        "\t`close` double NULL,\n",
        "\t`volume` bigint(20) NULL,\n",
        "\t`Name` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL,\n",
        "\t SHARD KEY ()\n",
        ");"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e4c15a63-eb17-432d-b0b5-d7485bcf028d",
      "metadata": {},
      "source": [
        "## Create a pipeline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "09616d12-05b7-4701-8f7d-37926aa78e7e",
      "metadata": {},
      "source": [
        "We then create a pipeline by pointing the data source to the S3 bucket containing the dataset. In our case, we have a CSV file `all_stocks_5yr.csv` and will be ingesting it into our `Stocks` table via a pipeline `stocks_pipeline`.\n",
        "\n",
        "To create your own pipeline, you will need the following information:\n",
        "\n",
        "- The path of the bucket, such as: `'helios-self-poc-stockticker/all_stocks_5yr.csv'`\n",
        "- The name of the bucket\u2019s region, such as: `us-east-1`\n",
        "- Your AWS account\u2019s access credentials: `<aws_access_key_id>` and `<aws_secret_access_key>`\n",
        "\n",
        "*For more on how to retrieve the above information, read our [Pipeline Documentation](https://docs.singlestore.com/cloud/load-data/load-data-with-pipelines/how-to-load-data-using-pipelines/load-data-from-amazon-web-services-aws-s-3/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "46229b29-7361-424e-86cf-31aa195df2d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE OR REPLACE PIPELINE stocks_pipeline\n",
        "    AS LOAD DATA S3 'helios-self-poc-stockticker/all_stocks_5yr.csv'\n",
        "    CONFIG '{\"region\": \"us-east-1\"}'\n",
        "    CREDENTIALS '{\"aws_access_key_id\": \"<your_key>\",\n",
        "                  \"aws_secret_access_key\": \"<your_secret>\"}'\n",
        "    BATCH_INTERVAL 45000\n",
        "    SKIP DUPLICATE KEY ERRORS -- SKIP ALL ERRORS can be used to skip all errors that can be tracked through \"Monitor the pipeline for errors\"\n",
        "    INTO TABLE stocks\n",
        "    FIELDS TERMINATED BY ',' ENCLOSED BY '\"' ESCAPED BY '\\\\'\n",
        "    LINES TERMINATED BY '\\n' STARTING BY ''\n",
        "    IGNORE 1 LINES\n",
        "    FORMAT CSV\n",
        "    (\n",
        "    \t`stocks`.`date`,\n",
        "    \t`stocks`.`open`,\n",
        "    \t`stocks`.`high`,\n",
        "    \t`stocks`.`low`,\n",
        "    \t`stocks`.`close`,\n",
        "    \t`stocks`.`volume`,\n",
        "    \t`stocks`.`Name`\n",
        "    );"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5410c1b9-573f-4326-ba4c-b7af71e069ad",
      "metadata": {},
      "source": [
        "## Start and monitor the pipeline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "acdb8cb7-3765-4503-a2fb-0e86b811431f",
      "metadata": {},
      "source": [
        "The CREATE PIPELINE statement creates a new pipeline, but the pipeline has not yet been started, and no data has been loaded. To start a pipeline in the background, run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eeddd12e-e28c-4000-859b-6d1291c4a137",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "START PIPELINE stocks_pipeline;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1f2894a3-31fe-4363-a75d-d72569d9918b",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "show pipelines;"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a555997d-38dc-4b69-821b-390e52bb4d00",
      "metadata": {},
      "source": [
        "If there is no error or warning, you should see no error message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f48de155-af85-4c40-ad56-955573a434f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "SELECT * FROM information_schema.pipelines_errors\n",
        "    WHERE pipeline_name = 'stocks_pipeline';"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c18ac453-63de-424a-b9bf-ae6846817ea6",
      "metadata": {},
      "source": [
        "## Query the table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "09a739cb-4925-4699-ab61-71016a04bfb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "SELECT * FROM stocks LIMIT 5;"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c4815572-10d8-4c31-a246-05ad6e7e6e99",
      "metadata": {},
      "source": [
        "## Cleanup resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6a6dfc1d-c758-4287-a797-6cc3e4fff934",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "DROP PIPELINE IF EXISTS test.stocks_pipeline;\n",
        "DROP TABLE IF EXISTS test.stocks;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c572193e-7f5b-4637-af5d-2f33f5ba5d86",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n",
        "<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"
      ]
    }
  ],
  "metadata": {
    "jupyterlab": {
      "notebooks": {
        "version_major": 6,
        "version_minor": 4
      }
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
