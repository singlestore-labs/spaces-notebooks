{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8e19358e-22e8-406c-ae17-d916db889313",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(210, 255, 153, 0.25); padding: 5px;\">\n",
        "    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n",
        "        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/chart-network.png\" />\n",
        "    </div>\n",
        "    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n",
        "        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n",
        "        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Semantic Search with Hugging Face Models and Datasets</h1>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60eb6690",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Note</b></p>\n",
        "        <p>This notebook can be run on a Free Starter Workspace. To create a Free Starter Workspace navigate to <tt>Start</tt> using the left nav. You can also use your existing Standard or Premium workspace with this Notebook.</p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bebf253-7913-4d7a-8ebc-f10463803baa",
      "metadata": {},
      "source": [
        "In this notebook, we will demonstrate an example of conducting semantic search on SingleStoreDB with SQL! Unlike traditional keyword-based search methods, semantic search algorithms take into account the relationships between words and their meanings, enabling them to deliver more accurate and relevant results \u2013 even when search terms are vague or ambiguous.\n",
        "\n",
        "SingleStoreDB\u2019s built-in parallelization and Intel SIMD-based vector processing takes care of the heavy lifting involved in processing vector data. This allows your to run your ML algorithms right in your database extremely efficiently with just 1 line of SQL!\n",
        "\n",
        "In this example, we use Hugging Face to create embeddings for our dataset and run semantic_search using dot_product vector matching function!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "358d1eb0-a0dd-423d-86ea-0d131abe4169",
      "metadata": {},
      "source": [
        "## 1. Create a workspace in your workspace group\n",
        "\n",
        "S-00 is sufficient.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p> If you have a Free Starter Workspace deployed already, select the database from drop-down menu at the top of this notebook. It updates the <tt>connection_url</tt> to connect to that database.</p>\n",
        "    </div>\n",
        "</div>\n",
        "\n",
        "## 2. Create a database named `semantic_search`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "af5e02fb-e15b-4c85-ac69-a40dd974cd88",
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_tier_check = %sql show variables like 'is_shared_tier'\n",
        "if not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n",
        "    %sql DROP DATABASE IF EXISTS semantic_search;\n",
        "    %sql CREATE DATABASE semantic_search;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "284f2bdc-a428-4a55-9f1f-fce623914b34",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p>Make sure to select the <tt>semantic_search</tt> database from the drop-down menu at the top of this notebook.\n",
        "        It updates the <tt>connection_url</tt> which is used by the <tt>%%sql</tt> magic command and SQLAlchemy to make connections to the selected database.</p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8124ab1c-7f17-47bc-9f8a-c7bd5a33a426",
      "metadata": {},
      "source": [
        "## 3. Install and import required libraries\n",
        "\n",
        "We will use an embedding model on Hugging Face with Sentence Transfomers library. We will be analysing the sentiment of reviewers of selected movies. This dataset is available on Hugging Face and to use it, we will need the datasets library.\n",
        "\n",
        "The install process may take a couple minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "af6146b2-a044-4dd8-b020-e3d8c1f91aba",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install sentence-transformers==2.2.2 torch==2.1.0 tensorflow==2.15.0 datasets==2.15.0 --quiet\n",
        "\n",
        "import json\n",
        "import ibis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sqlalchemy as sa\n",
        "import singlestoredb as s2\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f80d23bc-7e98-4ac8-b2a0-7a737e4010e5",
      "metadata": {},
      "source": [
        "## 4. Load Sentence Transformer library and create a function called `get_embedding()`\n",
        "\n",
        "To vectorize and embed the reviews that watchers of the movies left, we will be using the `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` model. We will create a function called `get_embedding()` that will call this model and return the vectorized version of the sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a463c0fd-c747-4605-a728-c22a2fa17cfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Sentence Transformers model\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac82174-a2a3-40aa-b843-235a7547cace",
      "metadata": {},
      "source": [
        "Add a function to compute the embedding. The result will be a numpy array of 32-bit floats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f2e31300-1e6a-425c-bcf7-3708ce9e40d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_embedding(sentence: str) -> np.ndarray[np.float32]:\n",
        "    \"\"\"Retrieve embedding for given sentence.\"\"\"\n",
        "    inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        embedding = model(**inputs).last_hidden_state.mean(dim=1).squeeze().tolist()\n",
        "    return np.array(embedding, dtype='<f4')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17fb3aad-e3a8-4a2a-985c-64f0c94431b8",
      "metadata": {},
      "source": [
        "## 5. Load the dataset on movie reviews from Hugging Face into a `DataFrame`\n",
        "\n",
        "We will be doing some operations and only sampling 100 random reviews from the \"test\" dataset of `imdb-movie-reviews`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e3af3810-0ce5-432b-a879-4eaa16524d38",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset into a pandas DataFrame\n",
        "dataset = load_dataset(\"ajaykarthick/imdb-movie-reviews\")\n",
        "dataframe = dataset[\"train\"].to_pandas()\n",
        "\n",
        "sample_size = 100  # Adjust the desired sample size\n",
        "random_sample = dataframe.sample(n=sample_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07a15a81-1312-4984-b7d9-8539a64c719f",
      "metadata": {},
      "source": [
        "## 6. Generate embeddings of the reviews left by customers and add them to your `DataFrame`\n",
        "\n",
        "We want to embed the entries in the `review` column and add the embeddings to the data. We will do this with pandas and our `get_embeddings` function. Embeddings are stored as a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2749ea9d-de63-4058-b682-faa9ec002d60",
      "metadata": {},
      "outputs": [],
      "source": [
        "random_sample['review_embeddings'] = random_sample['review'].apply(get_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8188ccb2-d5cf-48b5-8c9f-8b3858c18ae7",
      "metadata": {},
      "source": [
        "## 7. Insert data into SingleStoreDB\n",
        "\n",
        "You can seamlessly bring this data to your SingleStoreDB table directly from your from `DataFrame`. SingleStore \u2665\ufe0f Python.\n",
        "\n",
        "We will bring this data into a table called `reviews`. Notice how you don't have to write any SQL for this\u00a0\u2013\u00a0we will infer the schema from your `DataFrame` and underneath the hood configure how to bring this `DataFrame` into our database. Since numpy arrays don't map directly to a database type, we give pandas a type hint to create a blob column for the `review_embeddings` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9bd03799-b221-4dcd-9ce7-2db2b7ec1a8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "random_sample.to_sql('reviews',\n",
        "                     s2.create_engine().connect(),\n",
        "                     if_exists='replace',\n",
        "                     index=False,\n",
        "                     dtype=dict(review_embeddings=sa.LargeBinary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "23f900f5-eb39-413e-b414-a29cfafa60ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a database connection and display the `CREATE TABLE` statement\n",
        "conn = s2.connect()\n",
        "\n",
        "conn.show.create_table('reviews')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e34e62fb-7690-4a31-a874-ff7856d16cc7",
      "metadata": {},
      "source": [
        "## 8. Run the semantic search algorithm with just one line of SQL\n",
        "\n",
        "We will utilize SingleStoreDB's distributed architecture to efficiently compute the dot product of the input string (stored in searchstring) with each entry in the database and return the top 5  reviews with the highest dot product score. Each vector is normalized to length 1, hence the dot product function essentially computes the cosine similarity between two vectors \u2013 an appropriate nearness metric. SingleStoreDB makes this extremely fast because it compiles queries to machine code and runs dot_product using SIMD instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "08bd6b1c-9731-4062-9b9a-a5e1a1d8efa3",
      "metadata": {},
      "outputs": [],
      "source": [
        "searchstring = input('Please enter a search string:')\n",
        "\n",
        "search_embedding = get_embedding(searchstring).tobytes().hex()\n",
        "\n",
        "results = %sql SELECT review, DOT_PRODUCT(review_embeddings, X'{{search_embedding}}') AS Score \\\n",
        "               FROM reviews ORDER BY Score DESC LIMIT 5;\n",
        "\n",
        "print()\n",
        "for i, res in enumerate(results):\n",
        "    print(f'{i + 1}: {res[0]} Score: {res[1]:.2f}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0383939d-7fd3-434d-a27b-952eeed40e5f",
      "metadata": {},
      "source": [
        "## 9. Clean up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c4abd0a",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p> If you created a new database in your Standard or Premium Workspace, you can drop the database by running the cell below. Note: this will not drop your database for Free Starter Workspaces. To drop a Free Starter Workspace, terminate the Workspace using the UI. </p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0e91592f-4856-4cab-b15e-23585f551ab3",
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_tier_check = %sql show variables like 'is_shared_tier'\n",
        "if not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n",
        "    %sql DROP DATABASE IF EXISTS semantic_search;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6829f66-b37e-493d-9631-6da519140485",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n",
        "<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
