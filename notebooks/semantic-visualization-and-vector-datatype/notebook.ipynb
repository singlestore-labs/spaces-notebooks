{
  "cells": [
    {
      "id": "26367f5e",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(210, 255, 153, 0.25); padding: 5px;\">\n",
        "    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n",
        "        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/chart-network.png\" />\n",
        "    </div>\n",
        "    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n",
        "        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n",
        "        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Semantic Visualization and Vector Datatype</h1>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "id": "8abb8215",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Note</b></p>\n",
        "        <p>This notebook can be run on a Free Starter Workspace. To create a Free Starter Workspace navigate to <tt>Start</tt> using the left nav. You can also use your existing Standard or Premium workspace with this Notebook.</p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "SingleStoreDB supports vector database processing, which allows you to store and search vector data.\n",
        "Vectors usually come from objects: text, images, video, audio, etc.\n",
        "In a vector space model, words with similar meanings, such as <i>\"happy\"</i> and <i>\"joyful,\"</i> are represented by vectors that lie in proximity, reflecting their semantic similarity.\n",
        "Vector database searches find data based on its content or meaning, even without exact matches."
      ],
      "id": "66c2ea71"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Create a workspace in your workspace group\n",
        "\n",
        "S-00 is sufficient.\n",
        "\n",
        "## 2. Create a database named `db_vector`"
      ],
      "id": "c1efbe85"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p> If you have a Free Starter Workspace deployed already, select the database from drop-down menu at the top of this notebook. It updates the <tt>connection_url</tt> to connect to that database.</p>\n",
        "    </div>\n",
        "</div>"
      ],
      "id": "834d7507"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_tier_check = %sql show variables like 'is_shared_tier'\n",
        "if not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n",
        "    %sql DROP DATABASE IF EXISTS db_vector;\n",
        "    %sql CREATE DATABASE db_vector;"
      ],
      "id": "1d6d455c"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p> Make sure to select a database from the drop-down menu at the top of this notebook. It updates the <tt>connection_url</tt>  to connect to that database.</p>\n",
        "    </div>\n",
        "</div>"
      ],
      "id": "180f3641"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create table `words` and insert the words into the table."
      ],
      "id": "aa7a4a14"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE TABLE /* Creating table for sample data. */ words(word varchar(25));\n",
        "\n",
        "INSERT INTO words VALUES (\"red\"), (\"potatoes\"), (\"soda\"), (\"cheese\"),\n",
        "                         (\"water\"), (\"blue\"), (\"crispy\"), (\"hamburger\"),\n",
        "                         (\"coffee\"), (\"green\"), (\"milk\"), (\"la croix\"),\n",
        "                         (\"yellow\"), (\"chocolate\"), (\"french fries\"),\n",
        "                         (\"latte\"), (\"cake\"), (\"brown\"), (\"cheeseburger\"),\n",
        "                         (\"espresso\"), (\"cheesecake\"), (\"black\"), (\"mocha\"),\n",
        "                         (\"fizzy\"), (\"carbon\"), (\"banana\"), (\"sunshine\"),\n",
        "                         (\"orange carrot\"), (\"sun\"), (\"hay\"), (\"cookies\"),\n",
        "                         (\"fish\"), ('king'), ('man'), ('woman'), ('queen'),\n",
        "                         ('Paris'), ('France'), ('Poland'), ('Warsaw'),\n",
        "                         ('prince'), ('throne'), ('Elizabeth'), ('ruler');"
      ],
      "id": "e1d38b42"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SHOW TABLES EXTENDED;"
      ],
      "id": "7cfb0013"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install and import required libraries\n",
        "In this section, we will set up the necessary environment by installing important libraries .\n",
        "\n",
        "The install process may take a couple minutes."
      ],
      "id": "5818d73b"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install --upgrade sentence-transformers torch tensorflow pandarallel --quiet"
      ],
      "id": "6c5421e5"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import several libraries for data manipulation (e.g., Pandas, NumPy), database connectivity (SQLAlchemy, SingleStoreDB), machine learning (PyTorch, Transformers), and parallel processing (pandarallel)."
      ],
      "id": "b83a712d"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import ibis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sqlalchemy as sa\n",
        "import singlestoredb as s2\n",
        "import torch\n",
        "from pandarallel import pandarallel\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "from sqlalchemy import *\n",
        "db_connection = create_engine(connection_url)\n",
        "pandarallel.initialize(nb_workers=2, progress_bar=True)"
      ],
      "id": "1e03f1e3"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Sentence Transformer model along with its tokenizer, making them ready for use in tasks like sentence embeddings or similarity calculations."
      ],
      "id": "5edb77c5"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Sentence Transformers model"
      ],
      "id": "b82fecbf"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "id": "07ce4e31"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load the data into dataframe from database table"
      ],
      "id": "ddef8850"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data into a DataFrame"
      ],
      "id": "8b410662"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = %sql  select * from words;\n",
        "\n",
        "df = pd.DataFrame(result)\n",
        "df"
      ],
      "id": "cbef4bf7"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Function to retrieve the embedding\n",
        "\n",
        "This function, named get_embedding, takes a <b>sentence</b> as input and returns its <b>embedding</b> using a pre-trained tokenizer and model. It tokenizes the sentence and returns the resulting embedding as a NumPy array with a float32 data type."
      ],
      "id": "a4d048d4"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_embedding(sentence: str) -> np.ndarray[np.float32]:\n",
        "    \"\"\"Retrieve embedding for given sentence.\"\"\"\n",
        "    inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        embedding = model(**inputs).last_hidden_state.mean(dim=1).squeeze().tolist()\n",
        "    return np.array(embedding, dtype='<f4')"
      ],
      "id": "08dc6881"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Apply the function `get_embedding`\n",
        "\n",
        "It adds a new column 'word_embeddings' to a DataFrame df by applying a function get_embedding in parallel to the 'word' column, aiming to calculate and store word embeddings for each word in the DataFrame. The parallel_apply function  leverages parallel processing capabilities for efficient computation."
      ],
      "id": "1d0547af"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply the function\n",
        "df['word_embeddings'] = df['word'].parallel_apply(get_embedding)"
      ],
      "id": "946f640e"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below code writes the DataFrame df to a SQL table named `words_table` using SingleStoreDB (s2). It replaces the existing table if it already exists, does not include an index column in the table, and specifies the data type for the `word_embeddings` column as LargeBinary."
      ],
      "id": "b99a81a7"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the table with vector embeddings\n",
        "df.to_sql(\n",
        "    'words_table',\n",
        "    s2.create_engine().connect(),\n",
        "    if_exists='replace',\n",
        "    index=False,\n",
        "    dtype=dict(word_embeddings=sa.LargeBinary),\n",
        ")"
      ],
      "id": "778e76ad"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualizing words\n",
        "Below code transforms word embeddings stored in the `word_embeddings` column of DataFrame df using t-SNE (t-Distributed Stochastic Neighbor Embedding), reducing the dimensionality to 2 components. The resulting transformed data is stored in the variable `vis_dims`, representing the two-dimensional visualization of the word embeddings."
      ],
      "id": "e78a01a2"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "matrix = df[\"word_embeddings\"]\n",
        "matrix = matrix.tolist()\n",
        "matrix"
      ],
      "id": "346ea3c9"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "matrix = np.asarray(matrix)\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Create a t-SNE model and transform the data\n",
        "tsne = TSNE(n_components=2, perplexity=10, random_state=42, init='random', learning_rate=200)\n",
        "vis_dims = tsne.fit_transform(matrix)\n",
        "vis_dims.shape"
      ],
      "id": "583e7119"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install the Matplotlib library using the pip package manager, allowing for the visualization of data and plots in Python."
      ],
      "id": "3ef02f0e"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ],
      "id": "90afcd01"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Matplotlib to create a scatter plot visualizing the 2D representation of word embeddings obtained from t-SNE. The code iterates through each word in the DataFrame df, extracts its coordinates from vis_dims, and annotates the corresponding point on the scatter plot with the word label. Finally, the plot is displayed using `plt.show()`."
      ],
      "id": "dd14cc00"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "\n",
        "labels = []\n",
        "x = [x for x,y in vis_dims]\n",
        "y = [y for x,y in vis_dims]\n",
        "for word in range(len(df)):\n",
        "    first_value = df['word'].iat[word]\n",
        "    labels.append(first_value)\n",
        "\n",
        "print(len(df))\n",
        "\n",
        "plt.scatter(x, y,alpha=0.3)\n",
        "\n",
        "for i in range(len(x)):\n",
        "    plt.scatter(x[i],y[i])\n",
        "    plt.annotate(\n",
        "        labels[i],\n",
        "        xy=(x[i], y[i]),\n",
        "        xytext=(5, 2),\n",
        "        textcoords='offset points',\n",
        "        ha='right',\n",
        "        va='bottom',\n",
        "    )\n",
        "\n",
        "plt.show();"
      ],
      "id": "f3394b79"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can insert words of your choice in the <i>  words </i> table  and execute all the cells above to visualize the semantic patterns."
      ],
      "id": "dc848797"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Introducing Vector Datatype"
      ],
      "id": "d37f2217"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see below `word_embeddings` column is `blob` datatype"
      ],
      "id": "99cd0b59"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "DESC words_table;"
      ],
      "id": "8f0eebf9"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT word, word_embeddings FROM words_table LIMIT 2;"
      ],
      "id": "fa8d1ec0"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This below line of code executes a SQL query on the `words_table`, selecting the `word` column and the hexadecimal representation of the `word_embeddings` column for the first row in the table using the `limit 1` clause."
      ],
      "id": "be1a5e6a"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT word, HEX(word_embeddings) FROM words_table LIMIT 1;"
      ],
      "id": "60689524"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below query extracts the `word` column and unpacks the JSON array stored in the `word_embeddings` column for the first row in the `words_table`, providing a more readable representation of the word embeddings."
      ],
      "id": "508faddf"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT word, JSON_ARRAY_UNPACK(word_embeddings) FROM words_table LIMIT 1;"
      ],
      "id": "d3fa6534"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Transition from BLOB to Vector datatype\n",
        "\n",
        "<p> 1. Add a new vector column to the right of the blob column.</p>\n",
        "<p> 2. Update the vector column with the data from the blob column.</p>\n",
        "<p> 3. Drop the blob column.</p>\n",
        "<p> 4. Rename the new vector column to the old blob column name. This will ensure any previous queries will still work, or at least require fewer changes.\n",
        "</p>"
      ],
      "id": "ca8ad8bd"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT VECTOR_NUM_ELEMENTS(word_embeddings) FROM words_table LIMIT 1;"
      ],
      "id": "f6e449f9"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "ALTER TABLE words_table ADD COLUMN emb2 vector(384) AFTER word_embeddings;\n",
        "UPDATE words_table SET emb2=word_embeddings;"
      ],
      "id": "d58eefb6"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT word, emb2, JSON_ARRAY_UNPACK(word_embeddings) FROM words_table LIMIT 1;"
      ],
      "id": "d40fe9ce"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "ALTER TABLE words_table DROP COLUMN word_embeddings;\n",
        "ALTER TABLE words_table CHANGE emb2 word_embeddings;"
      ],
      "id": "5bffb8aa"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "DESC words_table;"
      ],
      "id": "60a3d4bd"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Semantic Search of the word -sunshine &#127774; using Infix Operator\n",
        "\n",
        "Performing a semantic search for the word 'sunshine' to find contextually similar or related words and phrases based on their semantic meanings rather than exact lexical matches.\n",
        "\n",
        "The infix operators `<*>` and `<->` can be used to  facilitate DOT_PRODUCT and EUCLIDEAN_DISTANCE operations, respectively, providing a more concise query syntax compared to using the existing built-in functions such as DOT_PRODUCT(a, b) and EUCLIDEAN_DISTANCE(a, b)."
      ],
      "id": "02364df2"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT word_embeddings INTO @c from words_table WHERE word LIKE 'sunshine%';\n",
        "SELECT word, (@c<*>word_embeddings) AS score\n",
        "    FROM words_table\n",
        "    ORDER BY score desc\n",
        "    LIMIT 3;"
      ],
      "id": "98a39ef5"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean up"
      ],
      "id": "99b34b0a"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p> If you created a new database in your Standard or Premium Workspace, you can drop the database by running the cell below. Note: this will not drop your database for Free Starter Workspaces. To drop a Free Starter Workspace, terminate the Workspace using the UI. </p>\n",
        "    </div>\n",
        "</div>"
      ],
      "id": "90b0773b"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_tier_check = %sql show variables like 'is_shared_tier'\n",
        "if not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n",
        "    %sql DROP DATABASE IF EXISTS db_vector;"
      ],
      "id": "b4b02c5d"
    },
    {
      "id": "cf2b8a2b",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n",
        "<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
