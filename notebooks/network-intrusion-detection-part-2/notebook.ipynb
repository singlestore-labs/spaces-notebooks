{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d62916d4-c174-4708-92b1-b6940fa5a861",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\">\n",
        "    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n",
        "        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/browser.png\" />\n",
        "    </div>\n",
        "    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n",
        "        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n",
        "        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">IT Threat Detection, Part 2</h1>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc4742e",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b class=\"fa fa-solid fa-info-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Note</b></p>\n",
        "        <p>This tutorial is meant for Standard & Premium Workspaces. You can't run this with a Free Starter Workspace due to restrictions on Storage. Create a Workspace using +group in the left nav & select Standard for this notebook. Gallery notebooks tagged with \"Starter\" are suitable to run on a Free Starter Workspace </p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59521b37-8c16-4713-b341-dcf4d020ef88",
      "metadata": {},
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c649045f-0a53-4c49-88cb-0351e872d68c",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install tensorflow keras scikit-learn --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f3bb35f9-67ea-4a23-b713-888746494baf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow.keras.backend as K\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f949377-d93b-43d3-b9e1-2fb910f843fd",
      "metadata": {},
      "source": [
        "We'll define a Python context manager called `clear_memory()` using the **contextlib** module. This context manager will be used to clear memory by running Python's garbage collector (`gc.collect()`) after a block of code is executed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "00eccb20-5b95-4383-88c4-2dff1b494a1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import contextlib\n",
        "import gc\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def clear_memory():\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06e5a33-bf7f-41ea-85fd-1b13871c40e9",
      "metadata": {},
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7c77cf96-e3f7-4bed-9f7e-913f851367d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "with clear_memory():\n",
        "    model = keras.models.load_model('it_threat_model')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ed66c137-1023-4dce-b9ea-5e742099302e",
      "metadata": {},
      "outputs": [],
      "source": [
        "with clear_memory():\n",
        "    # Select the first layer\n",
        "    layer_name = 'dense'\n",
        "    intermediate_layer_model = Model(\n",
        "        inputs = model.input,\n",
        "        outputs = model.get_layer(layer_name).output\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3756497-a5a8-453a-9257-13ac0122a6ff",
      "metadata": {},
      "source": [
        "## Data Preparation\n",
        "\n",
        "We'll use the second file we downloaded earlier for testing purposes.\n",
        "\n",
        "### Review Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bc2325d6-a298-4916-bf33-7416b3b4ab25",
      "metadata": {},
      "outputs": [],
      "source": [
        "with clear_memory():\n",
        "    data = pd.read_csv('Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv')\n",
        "\n",
        "data.Label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c515eb7-1e06-4be3-993b-cc4483cb7bf6",
      "metadata": {},
      "source": [
        "### Clean Data\n",
        "\n",
        "We'll run a cleanup script from the previously downloaded GitHub repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "73e53251-5fd9-4fbd-856e-2bbc560a2924",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python DeepLearning-IDS/data_cleanup.py \"Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\" \"result22022018\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c1125c-bb62-40b8-b885-d5d9187b5f81",
      "metadata": {},
      "source": [
        "We'll now review the cleaned data from the previous step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "326a320a-9388-4108-a0f0-10520d25c2a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "with clear_memory():\n",
        "    data_22_cleaned = pd.read_csv('result22022018.csv')\n",
        "\n",
        "data_22_cleaned.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "66a13b5c-07b2-413b-9b77-ce490fa8507b",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_22_cleaned.Label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df41d065-924e-4de5-834c-967846688e13",
      "metadata": {},
      "source": [
        "We'll create a sample that encompasses all the distinct types of web attacks observed on this particular date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9f669747-2c58-4113-a099-070c5a08a492",
      "metadata": {},
      "outputs": [],
      "source": [
        "with clear_memory():\n",
        "    data_sample = data_22_cleaned[-2000:]\n",
        "\n",
        "data_sample.Label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "722010dd-2a2e-41a8-848f-bad78d0fa79f",
      "metadata": {},
      "source": [
        "## Get Connection Details\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p>Select the database from the drop-down menu at the top of this notebook. It updates the <b>connection_url</b> which is used by SQLAlchemy to make connections to the selected database.</p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "806149fa-bba9-42fd-b804-3b5964bceca5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlalchemy import *\n",
        "\n",
        "db_connection = create_engine(connection_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f5e79af-3991-45e1-845e-a24390437d56",
      "metadata": {},
      "source": [
        "## Queries\n",
        "\n",
        "Next, we'll perform queries on the test dataset and store the predicted and expected results, enabling us to construct a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ddcd73cd-0d87-4aaf-82be-5d7bd0e73566",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "for i in tqdm(range(0, len(data_sample), BATCH_SIZE)):\n",
        "    test_data = data_sample.iloc[i:i+BATCH_SIZE, :]\n",
        "\n",
        "    # Create vector embedding using the model\n",
        "    test_vector = intermediate_layer_model.predict(K.constant(test_data.iloc[:, :-1]))\n",
        "    query_results = []\n",
        "\n",
        "    for xq in test_vector.tolist():\n",
        "        # SQL query here, make sure it returns 'id' column\n",
        "        query_res = %sql SELECT id, EUCLIDEAN_DISTANCE(Model_Results, JSON_ARRAY_PACK('{{xq}}')) AS score FROM model_results WHERE score IS NOT NULL ORDER BY score ASC LIMIT 50;\n",
        "        query_results.append(pd.DataFrame(query_res))\n",
        "\n",
        "    for label, res in zip(test_data.Label.values, query_results):\n",
        "\n",
        "        if 'id' not in res.columns:\n",
        "            print(\"Column 'id' not found in res.\")\n",
        "            continue\n",
        "\n",
        "        if label == 'Benign':\n",
        "            y_true.append(0)\n",
        "        else:\n",
        "            y_true.append(1)\n",
        "\n",
        "        ids_to_count = [id.split('_')[0] for id in res['id']]\n",
        "        counter = Counter(ids_to_count)\n",
        "        # print(counter)\n",
        "\n",
        "        if counter.get('Bru') or counter.get('SQL'):\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_pred.append(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62a3faef-773d-48ed-82c7-63dca0e31e07",
      "metadata": {},
      "source": [
        "## Visualize Results\n",
        "\n",
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "28dde466-1dcc-4b5f-98a4-4e3ce31cf12c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objs as go\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Create a DataFrame from the confusion matrix\n",
        "conf_matrix_df = pd.DataFrame(\n",
        "    conf_matrix,\n",
        "    columns = ['Benign', 'Attack'],\n",
        "    index = ['Benign', 'Attack']\n",
        ")\n",
        "\n",
        "# Create an empty list to store annotations\n",
        "annotations = []\n",
        "\n",
        "# Define a threshold for text color\n",
        "thresh = conf_matrix_df.values.max() / 2\n",
        "\n",
        "# Loop through the confusion matrix and add annotations with text color based on the threshold\n",
        "for i in range(len(conf_matrix_df)):\n",
        "    for j in range(len(conf_matrix_df)):\n",
        "        value = conf_matrix_df.iloc[i, j]\n",
        "        text_color = \"white\" if value > thresh else \"black\"\n",
        "        annotations.append(\n",
        "            go.layout.Annotation(\n",
        "                x = j,\n",
        "                y = i,\n",
        "                text = str(value),\n",
        "                font = dict(color = text_color),\n",
        "                showarrow = False,\n",
        "            )\n",
        "        )\n",
        "\n",
        "# Create a heatmap trace with showscale set to False\n",
        "trace = go.Heatmap(\n",
        "    z = conf_matrix_df.values,\n",
        "    x = ['Benign', 'Attack'],\n",
        "    y = ['Benign', 'Attack'],\n",
        "    colorscale = 'Reds',\n",
        "    showscale = False\n",
        ")\n",
        "\n",
        "# Create the figure with heatmap and annotations\n",
        "fig = go.Figure(\n",
        "    data = [trace],\n",
        "    layout = {\n",
        "        \"title\": \"Confusion Matrix\",\n",
        "        \"xaxis\": {\"title\": \"Predicted\", \"scaleanchor\": \"y\", \"scaleratio\": 1},\n",
        "        \"yaxis\": {\"title\": \"Actual\"},\n",
        "        \"annotations\": annotations,\n",
        "        \"height\": 400,\n",
        "        \"width\": 400\n",
        "    }\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "abaddb79-c9ea-4331-968e-98cd540f034b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Define class labels\n",
        "class_labels = ['Benign', 'Attack']\n",
        "\n",
        "# Print confusion matrix with labels\n",
        "print(\"Confusion Matrix:\")\n",
        "for i in range(len(class_labels)):\n",
        "    for j in range(len(class_labels)):\n",
        "        print(f\"{class_labels[i]} (Actual) -> {class_labels[j]} (Predicted): {conf_matrix[i][j]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a212b279-edce-4b3b-ad82-3b4933b1b10f",
      "metadata": {},
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bdb00bdc-4264-4ee5-b953-fed3c7317dd6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "acc = accuracy_score(y_true, y_pred, normalize = True, sample_weight = None)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30a06f84-7d9c-48d2-9b59-5d0aafb9b328",
      "metadata": {},
      "source": [
        "### Per Class Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "46f58998-e5ce-4c31-9612-25669254e98c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate per class accuracy\n",
        "cmd = confusion_matrix(y_true, y_pred, normalize = \"true\").diagonal()\n",
        "per_class_accuracy_df = pd.DataFrame([(index, round(value,4)) for index, value in zip(['Benign', 'Attack'], cmd)], columns = ['type', 'accuracy'])\n",
        "per_class_accuracy_df = per_class_accuracy_df.round(2)\n",
        "display(per_class_accuracy_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18da66d1-fa5f-4c0a-913f-915fc49c9411",
      "metadata": {},
      "source": [
        "## Predict Values Directly from Model\n",
        "\n",
        "We achieved excellent results with SingleStoreDB. Now, let's explore what happens when we bypass the similarity search step and make predictions directly from the model. In other words, we'll utilize the model responsible for generating the embeddings as a classifier. We can then compare the accuracy of this approach with that of the similarity search method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1ae8e5cb-c0fe-46e1-950f-3274644d869d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import normalize\n",
        "import numpy as np\n",
        "\n",
        "data_sample = normalize(data_22_cleaned.iloc[:, :-1])[-2000:]\n",
        "y_pred_model = model.predict(normalize(data_sample)).flatten()\n",
        "y_pred_model = np.round(y_pred_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23953237-8c81-4fe3-bead-aacbcc994c05",
      "metadata": {},
      "source": [
        "## Visualize Results\n",
        "\n",
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ce2b6188-5fab-4ee8-ad0b-8e10f11215fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_model)\n",
        "\n",
        "# Create a DataFrame from the confusion matrix\n",
        "conf_matrix_df = pd.DataFrame(\n",
        "    conf_matrix,\n",
        "    columns = ['Benign', 'Attack'],\n",
        "    index = ['Benign', 'Attack']\n",
        ")\n",
        "\n",
        "# Create an empty list to store annotations\n",
        "annotations = []\n",
        "\n",
        "# Define a threshold for text color\n",
        "thresh = conf_matrix_df.values.max() / 2\n",
        "\n",
        "# Loop through the confusion matrix and add annotations with text color based on the threshold\n",
        "for i in range(len(conf_matrix_df)):\n",
        "    for j in range(len(conf_matrix_df)):\n",
        "        value = conf_matrix_df.iloc[i, j]\n",
        "        text_color = \"white\" if value > thresh else \"black\"\n",
        "        annotations.append(\n",
        "            go.layout.Annotation(\n",
        "                x = j,\n",
        "                y = i,\n",
        "                text = str(value),\n",
        "                font = dict(color=text_color),\n",
        "                showarrow = False,\n",
        "            )\n",
        "        )\n",
        "\n",
        "# Create a heatmap trace with showscale set to False\n",
        "trace = go.Heatmap(\n",
        "    z = conf_matrix_df.values,\n",
        "    x = ['Benign', 'Attack'],\n",
        "    y = ['Benign', 'Attack'],\n",
        "    colorscale = 'Reds',\n",
        "    showscale = False\n",
        ")\n",
        "\n",
        "# Create the figure with heatmap and annotations\n",
        "fig = go.Figure(\n",
        "    data = [trace],\n",
        "    layout = {\n",
        "        \"title\": \"Confusion Matrix\",\n",
        "        \"xaxis\": {\"title\": \"Predicted\", \"scaleanchor\": \"y\", \"scaleratio\": 1},\n",
        "        \"yaxis\": {\"title\": \"Actual\"},\n",
        "        \"annotations\": annotations,\n",
        "        \"height\": 400,\n",
        "        \"width\": 400\n",
        "    }\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c9621933-9b22-4536-bf7a-6c1c78c4ac4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_model)\n",
        "\n",
        "# Define class labels\n",
        "class_labels = ['Benign', 'Attack']\n",
        "\n",
        "# Print confusion matrix with labels\n",
        "print(\"Confusion Matrix:\")\n",
        "for i in range(len(class_labels)):\n",
        "    for j in range(len(class_labels)):\n",
        "        print(f\"{class_labels[i]} (Actual) -> {class_labels[j]} (Predicted): {conf_matrix[i][j]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7168534e-77c1-440f-b55a-7fad84af37aa",
      "metadata": {},
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9ad16de3-2eb6-4ae3-b269-76c1f131fe63",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "acc = accuracy_score(y_true, y_pred_model, normalize = True, sample_weight = None)\n",
        "precision = precision_score(y_true, y_pred_model)\n",
        "recall = recall_score(y_true, y_pred_model)\n",
        "\n",
        "print(f\"Accuracy: {acc:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b80e72e5-814c-4533-9685-b126a0b481e7",
      "metadata": {},
      "source": [
        "### Per Class Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "bc88066d-df3b-48be-9ff6-246587e6630c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate per class accuracy\n",
        "cmd = confusion_matrix(y_true, y_pred_model, normalize = \"true\").diagonal()\n",
        "per_class_accuracy_df = pd.DataFrame([(index, round(value,4)) for index, value in zip(['Benign', 'Attack'], cmd)], columns = ['type', 'accuracy'])\n",
        "per_class_accuracy_df = per_class_accuracy_df.round(2)\n",
        "display(per_class_accuracy_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5455ba06-f2ba-4e2e-9494-c65ab2d9d96c",
      "metadata": {},
      "source": [
        "# Conclusions\n",
        "\n",
        "Utilizing SingleStoreDB's vector embeddings, we achieved an extremely high detection rate for attacks while maintaining a very small false-positive rate. Furthermore, our example showed that our similarity search methodology surpassed the direct classification approach that relies on the classifier's embedding model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f7e1cd9-615c-40cf-ac02-de9b51f0fa24",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n",
        "<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
