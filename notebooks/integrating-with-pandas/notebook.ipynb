{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c33f6a3-69f0-400d-813f-3889b1c08d2b",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\">\n",
        "    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n",
        "        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/database.png\" />\n",
        "    </div>\n",
        "    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n",
        "        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n",
        "        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Integrating pandas with SingleStoreDB</h1>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "084012cb-df73-4887-a105-9d82e2755508",
      "metadata": {},
      "source": [
        "This notebook will show how to move data from a pandas `DataFrame` into SingleStoreDB as well\n",
        "as downloading a SingleStoreDB query to a pandas `DataFrame`. It should be noted that this\n",
        "is only intended for relatively small data sets and to do processing that can't otherwise\n",
        "be done in SingleStoreDB itself. Moving data to the client for processing should only be done\n",
        "when there is no other alternative in the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9d6f398e-e63c-4477-ab37-fbdcdd2d92f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import ibis\n",
        "import pandas as pd\n",
        "import singlestoredb as s2\n",
        "import sqlalchemy as sa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b83e421-0ae5-46b3-a64d-25d77de7da0c",
      "metadata": {},
      "source": [
        "## Create a database\n",
        "\n",
        "We need to create a database to work with in the following examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7b0ca2e7-52ec-4d97-b3e6-31ee4a2bd466",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "DROP DATABASE IF EXISTS pandas_integration;\n",
        "CREATE DATABASE IF NOT EXISTS pandas_integration;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641ab7fd-a344-42f0-9cd9-755056374581",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n",
        "    <div>\n",
        "        <p><b>Action Required</b></p>\n",
        "        <p>Make sure to select the <tt>pandas_integration</tt> database from the drop-down menu at the top of this notebook.\n",
        "        It updates the <tt>connection_url</tt> to connect to that database.</p>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f094c4b2-dade-4432-9173-db590e7cb1dd",
      "metadata": {},
      "source": [
        "## Database connections\n",
        "\n",
        "In the notebooks environment, the connection string for the currently selected database is kept\n",
        "in the `connection_url` variable as well as the `SINGLESTOREDB_URL` environment variable.\n",
        "The connection variables are accessed automatically within the SingleStoreDB Python packages\n",
        "so that you do not need connection parameters when connecting.\n",
        "\n",
        "In the following sections, we will connect to SingleStoreDB using each of the packages and demonstrate\n",
        "techniques for moving data between pandas and SingleStoreDB."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6ffcb91-b70b-4175-bad7-7d087483e66b",
      "metadata": {},
      "source": [
        "## The Iris data set\n",
        "\n",
        "We'll be using the Iris data set for the following examples. This data set includes five columns: `sepal_length`,\n",
        "`sepal_width`, `petal_length`, `petal_width` and `class`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "68129a0f-7bb7-4c1b-bdab-dbb5c8cb43a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = pd.read_csv('https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/'\n",
        "                   'master/notebooks/integrating-with-pandas/data/iris.csv')\n",
        "iris"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5ef64c-1046-4db0-bb96-dd976c42db39",
      "metadata": {},
      "source": [
        "As you can see below, the first four columns are floats and the last column is a string\n",
        "(represented as an `object` in `DataFrame`s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "22392542-a71a-484b-9a3a-7e767d3bad07",
      "metadata": {},
      "outputs": [],
      "source": [
        "iris.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ea1fa0c-247e-4aaa-98a1-0980921fcaf7",
      "metadata": {},
      "source": [
        "## Moving data between SingleStoreDB and pandas `DataFrame`s\n",
        "\n",
        "Moving data from pandas `DataFrame`s to SingleStoreDB tables can be done in various ways from Python and even\n",
        "from each of the packages described here. This reference is to show the best techniques when using each\n",
        "package.\n",
        "\n",
        "It should be noted that moving data back-and-forth between pandas and SingleStoreDB should only be done when\n",
        "absolutely needed since this can be a major bottleneck when working with and analyzing data. The hope is that\n",
        "the features of SingleStoreDB are sufficient enough to alleviate the need to do much processing (if any) on\n",
        "the client machine."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d88c47a-7416-4566-b026-3e232afa7bc7",
      "metadata": {},
      "source": [
        "### SingleStoreDB Python\n",
        "\n",
        "The core library is the SingleStoreDB Python package. This is the package that all other SingleStoreDB\n",
        "packages are built on. To connect, simply call the `connect` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a36c4a90-0aeb-402a-8454-764730ac4a08",
      "metadata": {},
      "outputs": [],
      "source": [
        "s2_conn = s2.connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e54271f-e185-4965-bfaf-2639c304d503",
      "metadata": {},
      "source": [
        "Since the core library is a fairly low-level interface to SingleStoreDB, most operations are done simply by sending\n",
        "SQL code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46f57610-87bd-45c8-84bd-e77c9b313527",
      "metadata": {},
      "source": [
        "#### Creating a table\n",
        "\n",
        "Because we are using a low-level driver, creating a table is just done using SQL code. We'll use the information\n",
        "about the data set above to construct a `CREATE TABLE` statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4dc666be-0ce7-46bb-9afe-19f3435f02ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "s2_cur = s2_conn.cursor()\n",
        "s2_cur.execute(r'''\n",
        "    CREATE TABLE IF NOT EXISTS iris (\n",
        "        sepal_length DOUBLE,\n",
        "        sepal_width DOUBLE,\n",
        "        petal_length DOUBLE,\n",
        "        petal_width DOUBLE,\n",
        "        class TEXT\n",
        "    )\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c23826-1862-48ec-a837-a3e25ea52362",
      "metadata": {},
      "source": [
        "#### Upload the data from a `DataFrame`\n",
        "\n",
        "Now that we have a table, we can populate it with data from the `DataFrame`. Again, we will use\n",
        "SQL statements to do this. The Python client can execute single SQL statements using the\n",
        "`execute` method as used above, but since we are uploading multiple rows of data it is better\n",
        "to use the `executemany` method since it is optimized for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c7347b35-f82d-4bf4-bc7d-75a1ecd478e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construct the list of column names\n",
        "cols = ', '.join(f'`{x}`' for x in iris.columns)\n",
        "\n",
        "# Construct a list of value placeholders for the INSERT statement\n",
        "values = ', '.join(['%s'] * len(iris.columns))\n",
        "\n",
        "# Get data as a list of tuples (not including the index)\n",
        "data = list(iris.itertuples(index=False))\n",
        "\n",
        "# Execute the INSERT statement\n",
        "s2_cur.executemany(f'INSERT INTO iris({cols}) VALUES ({values})', data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4846819-8043-4917-8b37-20ed4b4ab7ab",
      "metadata": {},
      "source": [
        "We can select a sample of the rows to see that the data is now in SingleStoreDB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "801a8262-375a-40fc-8b2c-c15a8cee61a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "s2_cur.execute('SELECT * FROM iris LIMIT 10')\n",
        "for row in s2_cur:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3de53a-76a8-44f5-a999-364692df4601",
      "metadata": {},
      "source": [
        "#### Downloading the data to a `DataFrame`\n",
        "\n",
        "We can download the data to a pandas `DataFrame` simply by selecting all columns of data,\n",
        "fetching all of the rows, and passing them to the `DataFrame` constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "de9bf4d0-72be-4f70-9efa-129b041acba6",
      "metadata": {},
      "outputs": [],
      "source": [
        "s2_cur.execute('SELECT * FROM iris')\n",
        "\n",
        "# Use the `description` attribute to get the column names\n",
        "names = [x[0] for x in s2_cur.description]\n",
        "\n",
        "s2_iris_df = pd.DataFrame(list(s2_cur), columns=names)\n",
        "s2_iris_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ff2f9043-a940-43dc-974a-162e8bd2d576",
      "metadata": {},
      "outputs": [],
      "source": [
        "s2_iris_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "809ccd96-f00b-49ff-b19c-48d9b85c7e3f",
      "metadata": {},
      "source": [
        "Now that we have demonstrated uploading and downloading data from a pandas `DataFrame` using the\n",
        "SingleStoreDB Python client, we can drop the table and move on to SQLAlchemy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8ef3cbb3-0f01-47c4-b27f-0dcf5729e7cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "s2_cur.execute('DROP TABLE IF EXISTS iris')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75788e0a-df76-4be7-8ced-d01fdc37d7b6",
      "metadata": {},
      "source": [
        "### SQLAlchemy\n",
        "\n",
        "In addition to the core Python library, you can use SQLAlchemy to connect to SingleStoreDB. Typically, when\n",
        "using SQLAlchemy, you would use the SQLAlchemy `create_engine` function to create an engine, then call `connect`\n",
        "on the engine to create connections from a pool. The SingleStoreDB Python package also has a `create_engine`\n",
        "function that does the same thing, however, it extends the default ability by allow you to use the\n",
        "`SINGLESTOREDB_URL` environment variable as the connection string so that no parameters are needed for\n",
        "`create_engine` when used in the notebooks environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ea6ac741-7c01-4b34-95c8-59d97db70cab",
      "metadata": {},
      "outputs": [],
      "source": [
        "sa_eng = s2.create_engine()\n",
        "sa_conn = sa_eng.connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0f0463a-9796-4f23-8081-6589fce6463d",
      "metadata": {},
      "source": [
        "#### Uploading the data from a `DataFrame`\n",
        "\n",
        "Uploading data from a `DataFrame` using SQLAlchemy is much easier than the lower-level Python library.\n",
        "The pandas library itself has the ability to communicate with SingleStoreDB using a SQLAlchemy connection.\n",
        "In this case, the `DataFrame` can create the table and populate it in one step using the `to_sql` method.\n",
        "The `to_sql` method has various options to modify its behavior [documented on the pandas web site](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "de2c953c-09b9-4aa9-b491-751929322c19",
      "metadata": {},
      "outputs": [],
      "source": [
        "iris.to_sql('iris', con=sa_conn, index=False, if_exists='replace')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4574813-c134-4c0a-8915-94c0c466863f",
      "metadata": {},
      "source": [
        "We can verify the data is in SingleStoreDB with a simple `SELECT` statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6068dabe-5347-4449-926d-f52c0fb58b13",
      "metadata": {},
      "outputs": [],
      "source": [
        "for row in sa_conn.execute(sa.text('SELECT * FROM iris LIMIT 10')):\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75b0a1ee-8c21-4b8a-856e-643485661bdf",
      "metadata": {},
      "source": [
        "It is also possible to use SQLAlchemy expressions to query the table rather than raw SQL strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "60e13489-3d70-48c1-b17b-baebb0d0543c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a metadata object for the database\n",
        "if sa.__version__.startswith('1'):\n",
        "    db = sa.MetaData(bind=sa_eng)\n",
        "    sa.MetaData.reflect(db)\n",
        "else:\n",
        "    db = sa.MetaData()\n",
        "    db.reflect(bind=sa_eng)\n",
        "\n",
        "# Get the iris table from reflected data\n",
        "sa_iris = db.tables['iris']\n",
        "\n",
        "# Query the iris table\n",
        "query = sa.select(sa_iris).limit(10)\n",
        "\n",
        "# Print results\n",
        "for row in sa_conn.execute(query):\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0db80753-98a7-4748-83fe-1190cd04415f",
      "metadata": {},
      "source": [
        "#### Downloading the data to a `DataFrame`\n",
        "\n",
        "Downloading data to a pandas `DataFrame` is very simple. The result of the `execute` method can\n",
        "be passed directly to the pandas `DataFrame` constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6053dcf8-8774-4e73-a5d7-2a86bb597569",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset query to not include the limit\n",
        "query = sa.select(sa_iris)\n",
        "\n",
        "sa_iris_df = pd.DataFrame(sa_conn.execute(query))\n",
        "sa_iris_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5c2a5a7b-a00d-48b5-8e8b-b19e08d5d792",
      "metadata": {},
      "outputs": [],
      "source": [
        "sa_iris_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8977c4c-a0a8-4299-b7bb-d1c03e386169",
      "metadata": {},
      "source": [
        "It is also possible to use `pd.read_sql` to bookend the use of `df.to_sql`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a200df59-efb2-42e6-bca5-1b115666fb2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "sa_iris_df = pd.read_sql(query, con=sa_conn)\n",
        "sa_iris_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1dd2d93-f330-4e3a-b39a-32accc3d1a60",
      "metadata": {},
      "source": [
        "Now that we have demonstrated using SQLAlchemy to upload and download pandas `DataFrames` we can drop\n",
        "the table and move on to Ibis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "65eb886b-cdb6-4dae-bfaf-57a03d23cd51",
      "metadata": {},
      "outputs": [],
      "source": [
        "sa_iris.drop(bind=sa_eng)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5693eca8-fa3c-46ad-94fb-73d02ca50478",
      "metadata": {},
      "source": [
        "### Ibis (SingleStoreDB DataFrame)\n",
        "\n",
        "The Ibis package allows you to treat tables in SingleStoreDB as `DataFrames`. The `DataFrame` expressions\n",
        "are used to build lazy expressions which generate SQL statements that get submitted to SingleStoreDB\n",
        "only when you want to see the results of a query. Ibis using SQLAlchemy connections behind-the-scenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "686b8296-d50e-4a0b-b464-8b7807417f79",
      "metadata": {},
      "outputs": [],
      "source": [
        "ibis_conn = ibis.singlestoredb.connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "254fd629-e321-434f-a257-ccc3874ac93b",
      "metadata": {},
      "source": [
        "#### Uploading the data from a `DataFrame`\n",
        "\n",
        "Ibis is intended for tight integration with pandas, so it is no surprise that uploading a\n",
        "pandas `DataFrame` with Ibis is straight-forward.\n",
        "\n",
        "If you are not familiar with Ibis, you may notice the `execute` call at the end of this cell.\n",
        "Ibis creates expressions in memory on the client machine until a view of the data is\n",
        "explicitly asked for. Once you explicitly ask for a query to be executed, it then generates\n",
        "and submits the SQL code for the expression behind-the-scenes.\n",
        "\n",
        "In this case, the `ibis_iris` object is a `DataFrame`-like object that is lazily constructing\n",
        "the requested expression until `execute` is called on it. In the case of this example, uploading\n",
        "and downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0ca99ab2-bd93-41da-98f7-82c0d9934f43",
      "metadata": {},
      "outputs": [],
      "source": [
        "ibis_iris = ibis_conn.create_table('iris', iris, overwrite=True)\n",
        "ibis_iris.limit(10).execute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49bb8050-a6f4-4a6d-b083-78b324ebc755",
      "metadata": {},
      "source": [
        "It is also possible to insert the data from a `DataFrame` into an existing table using the `insert` method\n",
        "of the connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d2841e5b-a8c9-41e3-a404-25d532e831d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "ibis_conn.insert('iris', iris)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60cc0488-04ae-4c8b-9641-f6ef07133ac8",
      "metadata": {},
      "source": [
        "You'll see that we now have 300 rows since we've inserted the data twice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bc49e1ac-25b3-49e6-a257-c2bf2ace5be7",
      "metadata": {},
      "outputs": [],
      "source": [
        "ibis_iris.count().execute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125cc52e-37fe-4c9f-a573-c81f6363ff36",
      "metadata": {},
      "source": [
        "One way to see the SQL that gets submitted during `execute` is to compile the expression\n",
        "and print it. Ibis also has a options to display SQL queries as they are submitted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a1e4ccba-bec5-451c-9fd1-4b0ba87e5a74",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(ibis_iris.compile())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11e9fa6e-bb62-488c-a530-835ebd41d323",
      "metadata": {},
      "source": [
        "The information about the table can be retrieved much like in a local pandas `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2bfbb75b-ef83-4400-9909-348a12ac83cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "ibis_iris.info().execute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bb2e364-b2c2-4c07-81ea-3e20dec1c723",
      "metadata": {},
      "source": [
        "#### Downloading the data from a `DataFrame`\n",
        "\n",
        "The output from evaluating Ibis expressions returns a `DataFrame`, so we have already demonstrated\n",
        "downloading data, but here is the code again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b9e14b01-9350-4560-81f9-cf68f4e105f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "ibis_iris_df = ibis_iris.execute()\n",
        "ibis_iris_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e399be8a-6c5b-46cd-9c6b-7b4d02a36e57",
      "metadata": {},
      "source": [
        "Ibis `Table`s also have a `to_pandas` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c6623479-e200-4575-ae12-e415feb11237",
      "metadata": {},
      "outputs": [],
      "source": [
        "ibis_iris.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15feee4b-746b-4333-aabf-c8c061db9bb0",
      "metadata": {},
      "source": [
        "If you do not have an Ibis object reference to a table already, you can get one using the `table` method\n",
        "or `tables` attribute of the Ibis connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b1479ee9-10c6-47ac-b54e-3b3032c04949",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use this version if the table name is not a valid Python variable name\n",
        "ibis_iris = ibis_conn.table('iris')\n",
        "\n",
        "# This form can be used if the table name is a valid Python variable name\n",
        "ibis_iris = ibis_conn.tables.iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "eec644ad-61e1-4ab7-9cb0-edf0ed2a1f81",
      "metadata": {},
      "outputs": [],
      "source": [
        "ibis_iris.limit(10).execute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef002757-d84c-4da2-a61c-48c424569261",
      "metadata": {},
      "source": [
        "We have demonstrated both uploading and downloading pandas `DataFrames` using Ibis, so\n",
        "we can drop the table now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e96373d5-651c-4047-bda7-3e49bf6edb7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "ibis_conn.drop_table('iris')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d885cce5-1ae9-43e1-ae13-6b98c43ca23b",
      "metadata": {},
      "source": [
        "### `%%sql` and `%sql` magic commands\n",
        "\n",
        "The IPython interpreter can be extended with \"magic\" commands. The SingleStore Cloud notebook environment\n",
        "uses the [JupySQL](https://jupysql.ploomber.io/en/latest/quick-start.html) plugin for the `%sql`, `%%sql`,\n",
        "and `%sqlplot` commands. These work in conjunction with SQLAlchemy to allow you to type SQL code in\n",
        "the notebook cells. They also have ways of integrating with pandas. The notebook environment automatically\n",
        "sets up the connection string for use in these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a474e845-0039-4625-a250-2ec5cf0adaaa",
      "metadata": {},
      "source": [
        "#### Creating a table\n",
        "\n",
        "Creating a table with the `%%sql` command is done simply by submitting the `CREATE TABLE` statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "db10dca0-b2c5-43c9-8dcc-1f520fac7efb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "DROP TABLE IF EXISTS iris;\n",
        "CREATE TABLE IF NOT EXISTS iris (\n",
        "    sepal_length DOUBLE,\n",
        "    sepal_width DOUBLE,\n",
        "    petal_length DOUBLE,\n",
        "    petal_width DOUBLE,\n",
        "    class TEXT\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0f53739-6d19-4be8-ae08-c5dca35acfef",
      "metadata": {},
      "source": [
        "#### Uploading the data from a `DataFrame`\n",
        "\n",
        "The `%sql` command has options that allow you to upload data from a `DataFrame`. The `--persist` option\n",
        "will create a table in the database and upload the data. The `--append` option will append data to an\n",
        "existing table. In this case, the name used for the `DataFrame` variable is used for the table name\n",
        "in SingleStoreDB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8839c965-880d-4909-88a0-b7fa8cb4723d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%sql --append --no-index iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f11d4a80-9555-4067-9ada-2e4cf3ead35f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT * FROM iris LIMIT 10;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da339a4c-84a6-4f7d-a802-4fdd9f40d2b9",
      "metadata": {},
      "source": [
        "#### Downloading the data from a `DataFrame`\n",
        "\n",
        "There are a few ways of getting data from SingleStoreDB into a `DataFrame` using the SQL magic commands.\n",
        "The first is to use the `%sql` command and convert the result manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4198f8b6-175d-4a16-963e-af7508e06487",
      "metadata": {},
      "outputs": [],
      "source": [
        "out = %sql SELECT * FROM iris\n",
        "sql_iris_df = out.DataFrame()\n",
        "sql_iris_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5978394-d1fe-4c24-a3bd-9b8ce9583dcc",
      "metadata": {},
      "source": [
        "You can also pass the result of the query to the `DataFrame` constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "4f008d44-efde-415c-b847-a7d351ac8157",
      "metadata": {},
      "outputs": [],
      "source": [
        "sql_iris_df = pd.DataFrame(out)\n",
        "sql_iris_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01076d35-e406-453a-88c5-86f70b98e55e",
      "metadata": {},
      "source": [
        "Finally, the output of the `%%sql` command can be stored to a variable which can then be\n",
        "converted to a `DataFrame` in the same manner as above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "2bb36229-b336-462f-977f-36679d40f50f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql result <<\n",
        "SELECT * FROM iris;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "2094aa36-86bf-469b-9322-a9f94877f954",
      "metadata": {},
      "outputs": [],
      "source": [
        "sql_iris_df = pd.DataFrame(result)\n",
        "sql_iris_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "285fcfbb-5487-4195-9240-8af8462115fe",
      "metadata": {},
      "source": [
        "##### Automatically return pandas `DataFrame`s\n",
        "\n",
        "The other option for getting `DataFrame`s as the result of the SQL magic commands is to enable\n",
        "the `SqlMagic.autopandas` option. This will cause all results from SQL magic commands to be\n",
        "converted to `DataFrame`s without any intervention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "f19aee9c-fe28-4c0b-a902-c094ea76cfd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "%config SqlMagic.autopandas = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6caba2b5-86b4-4abf-9063-e59bbac2aab3",
      "metadata": {},
      "outputs": [],
      "source": [
        "out = %sql SELECT * FROM iris\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "129603ca-b982-4b77-9967-8c0fe0520f45",
      "metadata": {},
      "outputs": [],
      "source": [
        "type(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "929f83b9-bb1c-4d6f-9a5e-fdfc8db0db7e",
      "metadata": {},
      "source": [
        "Now that we have demonstrated uploading and downloading of `DataFrame`s using the SQL magic commands,\n",
        "we can reset the configuration options and drop the table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "32a14f6f-7afa-442c-8e58-c317bccdbcb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "%config SqlMagic.autopandas = False\n",
        "%sql DROP TABLE IF EXISTS iris"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a832062-3934-4541-81b5-5c3cf0c117ac",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "We have shown how to upload and download data from a pandas `DataFrame` to and from SingleStoreDB\n",
        "using the SingleStoreDB Python client, SQLAlchemy, and Ibis. These techniques should enable you to\n",
        "integrate your pandas workflows with SingleStoreDB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "6d6f10e5-7605-485b-82f3-7a26a17ae912",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%sql\n",
        "DROP DATABASE IF EXISTS pandas_integration;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dca02e68-11a8-46b9-b2eb-35f466d0c96e",
      "metadata": {},
      "source": [
        "<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n",
        "<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"
      ]
    }
  ],
  "metadata": {
    "jupyterlab": {
      "notebooks": {
        "version_major": 6,
        "version_minor": 4
      }
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
